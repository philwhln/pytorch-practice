{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -yq git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/philwhln/pytorch-practice.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git -C pytorch-practice/ pull "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd() / \"pytorch-practice\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import dataloader_cifar10_animal_bird\n",
    "importlib.reload(dataloader_cifar10_animal_bird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf pytorch-practice/cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim, nn\n",
    "\n",
    "from dataloader_cifar10_animal_bird import prepare_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "    print(f'Training on device {device}')\n",
    "\n",
    "    learning_rate = 1e-2\n",
    "    batch_size = 1024\n",
    "    epochs = 200\n",
    "\n",
    "    train_loader, val_loader, class_names = prepare_data(batch_size, device=device)\n",
    "\n",
    "    in_shape = (32, 32, 3)\n",
    "    n_hidden = 512\n",
    "    n_out = len(class_names)\n",
    "\n",
    "    model = Net(*in_shape, n_hidden, n_out).to(device)\n",
    "\n",
    "    describe_params(model)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train(model, loss_fn, optimizer, train_loader, val_loader, device, epochs)\n",
    "\n",
    "\n",
    "def describe_params(model):\n",
    "    total_trainable_params = 0\n",
    "    for name, params in model.named_parameters():\n",
    "        num_params = params.numel()\n",
    "        trainable_params = 0\n",
    "        if params.requires_grad:\n",
    "            total_trainable_params += num_params\n",
    "            trainable_params = num_params\n",
    "        print(f'{name}: {params.shape} params={num_params} trainable={trainable_params})')\n",
    "    print(f'total trainable params : {total_trainable_params}')\n",
    "\n",
    "\n",
    "def train(model, loss_fn, optimizer, train_loader, val_loader, device, epochs):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        start_time = time()\n",
    "        train_accuracy, train_loss = one_epoch(model, loss_fn, device, train_loader, optimizer)\n",
    "        train_time = time() - start_time\n",
    "\n",
    "        # occasionally check validation set performance\n",
    "        if epoch % 5 == 0:\n",
    "            start_time = time()\n",
    "            val_accuracy, val_loss = one_epoch(model, loss_fn, device, val_loader)\n",
    "            val_time = time() - start_time\n",
    "            print(f'epoch = {epoch}  train loss = {train_loss:0.6f}  train accuracy = {train_accuracy}  '\n",
    "                  f'val loss = {val_loss:0.6f}  val accuracy = {val_accuracy}  '\n",
    "                  f'train time = {train_time:0.2f}  val time = {val_time:0.2f}')\n",
    "\n",
    "\n",
    "def one_epoch(model, loss_fn, device, data_loader, optimizer=None):\n",
    "\n",
    "    update_parameters = (optimizer is not None)\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss_accum = 0.\n",
    "\n",
    "    for imgs, label_indices in data_loader:\n",
    "        imgs = imgs.to(device=device)\n",
    "        label_indices = label_indices.to(device=device)\n",
    "\n",
    "        num_imgs = imgs.shape[0]\n",
    "\n",
    "        with torch.set_grad_enabled(update_parameters):\n",
    "            output = model(imgs)\n",
    "            loss = loss_fn(output, label_indices)\n",
    "\n",
    "        loss_accum += loss.item()\n",
    "\n",
    "        out_scores, out_indices = torch.max(output, dim=-1)\n",
    "        total += num_imgs\n",
    "        correct += int((out_indices == label_indices).sum())\n",
    "\n",
    "        if update_parameters:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    avg_loss = loss_accum / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def validation(model, loss_fn, data_loader, device):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss_accum = 0.\n",
    "\n",
    "    for imgs, label_indices in data_loader:\n",
    "        imgs = imgs.to(device=device)\n",
    "        label_indices = label_indices.to(device=device)\n",
    "\n",
    "        num_imgs = imgs.shape[0]\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            output = model(imgs)\n",
    "            loss = loss_fn(output, label_indices).item()\n",
    "\n",
    "        loss_accum += loss.item()\n",
    "\n",
    "        out_scores, out_indices = torch.max(output, dim=-1)\n",
    "        total += num_imgs\n",
    "        correct += int((out_indices == label_indices).sum())\n",
    "\n",
    "    avg_loss = loss_accum / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_width: int, input_height: int, input_channels: int, hidden_units: int, output_units: int):\n",
    "        super().__init__()\n",
    "        conv1_out_channels = 16\n",
    "        conv2_out_channels = 8\n",
    "        self.conv1 = nn.Conv2d(input_channels, conv1_out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(conv1_out_channels, conv2_out_channels, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(int(input_width / 2 / 2) * int(input_height / 2 / 2) * conv2_out_channels, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, output_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = torch.tanh(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = self.conv2(out)\n",
    "        out = torch.tanh(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, self.fc1.in_features)\n",
    "        out = self.fc1(out)\n",
    "        out = torch.tanh(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
